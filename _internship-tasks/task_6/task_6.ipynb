{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings ## importing warnings library \n",
    "warnings.filterwarnings('ignore') ## Ignore warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/anastasiiatrofymova/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/anastasiiatrofymova/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2b569abc-dd81-4a53-9b43-2cf127b23e58;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 220ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2b569abc-dd81-4a53-9b43-2cf127b23e58\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "24/09/27 11:57:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Delta Table Example\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Delta Table or Load a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------+--------+------------+-----+--------+\n",
      "|       impression_id|    impression_time|user_id|app_code|  os_version|is_4G|is_click|\n",
      "+--------------------+-------------------+-------+--------+------------+-----+--------+\n",
      "|c4ca4238a0b923820...|2018-11-15 00:00:00|  87862|     422|         old|    0|       0|\n",
      "|45c48cce2e2d7fbde...|2018-11-15 00:01:00|  63410|     467|      latest|    1|       1|\n",
      "|70efdf2ec9b086079...|2018-11-15 00:02:00|  71748|     259|intermediate|    1|       0|\n",
      "|8e296a067a3756337...|2018-11-15 00:02:00|  69209|     244|      latest|    1|       0|\n",
      "|182be0c5cdcd5072b...|2018-11-15 00:02:00|  62873|     473|      latest|    0|       0|\n",
      "|3416a75f4cea91095...|2018-11-15 00:03:00|  67352|     409|      latest|    1|       0|\n",
      "|f457c545a9ded88f1...|2018-11-15 00:03:00|  64356|     190|intermediate|    0|       0|\n",
      "|72b32a1f754ba1c09...|2018-11-15 00:04:00|  27329|     481|      latest|    0|       0|\n",
      "|fc490ca45c00b1249...|2018-11-15 00:05:00|  83318|     386|         old|    0|       0|\n",
      "|d2ddea18f00665ce8...|2018-11-15 00:05:00|  70206|     190|      latest|    0|       0|\n",
      "|43ec517d68b6edd30...|2018-11-15 00:06:00|  74339|     481|         old|    0|       1|\n",
      "|7647966b7343c2904...|2018-11-15 00:06:00|  62357|     385|      latest|    0|       0|\n",
      "|e2ef524fbf3d9fe61...|2018-11-15 00:07:00|  20273|     249|      latest|    0|       0|\n",
      "|65b9eea6e1cc6bb9f...|2018-11-15 00:08:00|  18206|     508|      latest|    1|       0|\n",
      "|73278a4a86960eeb5...|2018-11-15 00:08:00|  71748|     259|intermediate|    1|       0|\n",
      "|4c56ff4ce4aaf9573...|2018-11-15 00:09:00|  75546|     275|         old|    0|       0|\n",
      "|d1f491a404d685488...|2018-11-15 00:09:00|   4238|     371|      latest|    0|       0|\n",
      "|3988c7f88ebcb58c6...|2018-11-15 00:10:00|  42507|     207|      latest|    0|       0|\n",
      "|2b24d495052a8ce66...|2018-11-15 00:11:00|  91471|     499|      latest|    0|       0|\n",
      "|b3e3e393c77e35a4a...|2018-11-15 00:11:00|  42151|     372|         old|    0|       0|\n",
      "+--------------------+-------------------+-------+--------+------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema definition\n",
    "schema = StructType([\n",
    "    StructField(\"impression_id\", StringType(), True),\n",
    "    StructField(\"impression_time\", StringType(), True),\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"app_code\", IntegerType(), True),\n",
    "    StructField(\"os_version\", StringType(), True),\n",
    "    StructField(\"is_4G\", IntegerType(), True),\n",
    "    StructField(\"is_click\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Load data with schema applied\n",
    "path = \"impressions.csv\"\n",
    "df = spark.read.option(\"header\", True).schema(schema).csv(path)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 11:57:35 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "24/09/27 11:57:35 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------+--------+------------+-----+--------+\n",
      "|       impression_id|    impression_time|user_id|app_code|  os_version|is_4G|is_click|\n",
      "+--------------------+-------------------+-------+--------+------------+-----+--------+\n",
      "|e9ed0a38ae765e5c7...|2018-12-10 17:00:00|  37755|     386|      latest|    1|       0|\n",
      "|83aa8115e0c04ddb6...|2018-12-10 17:01:00|  13949|     386|         old|    1|       0|\n",
      "|46c529721b46a7461...|2018-12-10 17:02:00|  71261|     249|intermediate|    0|       0|\n",
      "|49b2e97d32e87b86a...|2018-12-10 17:03:00|  64600|     283|      latest|    0|       0|\n",
      "|a1dd77ee7f3501f1d...|2018-12-10 17:03:00|  86711|     318|      latest|    1|       0|\n",
      "|797ccff2ab7ec91ee...|2018-12-10 17:04:00|   1277|     504|         old|    1|       0|\n",
      "|911be73e46fe41d58...|2018-12-10 17:05:00|  35063|     207|      latest|    0|       0|\n",
      "|c7c3eda2bae16bbcf...|2018-12-10 17:06:00|  45027|     207|      latest|    0|       0|\n",
      "|39340ef0b0e146881...|2018-12-10 17:07:00|   9253|     463|      latest|    0|       0|\n",
      "|16837ebf9f28e480d...|2018-12-10 17:07:00|  91334|     207|         old|    0|       0|\n",
      "|2971eefd42c45cc5f...|2018-12-10 17:08:00|   2616|     359|      latest|    1|       0|\n",
      "|a8d02bbaa34badf68...|2018-12-10 17:09:00|  82804|     190|         old|    0|       0|\n",
      "|55d9bb8b86c88c99e...|2018-12-10 17:11:00|   6481|     256|      latest|    0|       0|\n",
      "|b9a29f9e165807aa8...|2018-12-10 17:13:00|  59433|      32|intermediate|    1|       0|\n",
      "|b4d37642078ea853c...|2018-12-10 17:14:00|  27090|     423|intermediate|    0|       0|\n",
      "|46061c93454106c4f...|2018-12-10 17:15:00|  75604|     318|      latest|    1|       0|\n",
      "|ee7e9626d8edccf97...|2018-12-10 17:15:00|  42497|     207|         old|    0|       0|\n",
      "|7997c382a9ad98db0...|2018-12-10 17:16:00|   5604|     190|      latest|    0|       0|\n",
      "|c76b3668e2df23a39...|2018-12-10 17:16:00|  37728|     207|      latest|    0|       0|\n",
      "|c4bf23f6c967e5fef...|2018-12-10 17:18:00|  56129|     207|      latest|    0|       0|\n",
      "+--------------------+-------------------+-------+--------+------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write DataFrame as Delta table\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"data/impressions_delta_table\")\n",
    "\n",
    "# Load Delta table\n",
    "delta_df = spark.read.format(\"delta\").load(\"data/impressions_delta_table\")\n",
    "delta_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------+--------+----------+-----+--------+\n",
      "|       impression_id|    impression_time|user_id|app_code|os_version|is_4G|is_click|\n",
      "+--------------------+-------------------+-------+--------+----------+-----+--------+\n",
      "|39af3153ae383ed71...|2018-11-24 01:35:00|  66498|     508|    latest|    1|       0|\n",
      "|50b581cac0dcc1672...|2018-11-24 01:37:00|  77000|     244|    latest|    1|       0|\n",
      "|277c3d058cb0490fa...|2018-11-24 01:39:00|  46028|     190|    latest|    0|       0|\n",
      "|bde2abe34297af7e0...|2018-11-24 01:44:00|  84806|     190|    latest|    0|       0|\n",
      "|bdc3472e51887357a...|2018-11-24 01:47:00|  73076|     473|    latest|    0|       0|\n",
      "|9a14ec361fce610fe...|2018-11-24 01:49:00|  85634|      32|    latest|    1|       0|\n",
      "|b2ad0e581e0195bcb...|2018-11-24 01:50:00|  82257|       3|    latest|    1|       0|\n",
      "|a2b490ed6409a7b13...|2018-11-24 01:53:00|  64412|      38|    latest|    0|       0|\n",
      "|298ba172091b07c23...|2018-11-24 01:54:00|  34412|       3|    latest|    1|       0|\n",
      "|e1f311762441bb48d...|2018-11-24 01:58:00|  16929|     372|    latest|    0|       0|\n",
      "|ec9858da4637f2291...|2018-11-24 02:04:00|  88589|     249|    latest|    0|       0|\n",
      "|02f38b70d904d7c0b...|2018-11-24 02:10:00|  59643|     465|    latest|    1|       0|\n",
      "|0ef369271418089b4...|2018-11-24 02:15:00|  38266|     190|    latest|    1|       0|\n",
      "|5d2903364418c3c09...|2018-11-24 02:17:00|  78796|     242|    latest|    1|       0|\n",
      "|01b7ebbc8e1990be2...|2018-11-24 02:21:00|  16918|       3|    latest|    1|       0|\n",
      "|56ce94779a45b9dec...|2018-11-24 02:24:00|  68640|     190|    latest|    0|       0|\n",
      "|b24f4ae2eb41a573e...|2018-11-24 02:28:00|  48834|     371|    latest|    0|       0|\n",
      "|b6e37fd3a77259371...|2018-11-24 02:32:00|  90201|     190|    latest|    1|       0|\n",
      "|71ec89d6a2089545c...|2018-11-24 02:34:00|  49039|     371|    latest|    1|       0|\n",
      "|99356a4254135f494...|2018-11-24 02:45:00|  10276|     207|    latest|    0|       0|\n",
      "+--------------------+-------------------+-------+--------+----------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Filter: Impressions for Users only with latest OS\n",
    "latest_os_df = delta_df.filter(F.col(\"os_version\") == 'latest')\n",
    "latest_os_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------+--------+----------+-----+--------+---------+\n",
      "|       impression_id|    impression_time|user_id|app_code|os_version|is_4G|is_click|dayofweek|\n",
      "+--------------------+-------------------+-------+--------+----------+-----+--------+---------+\n",
      "|39af3153ae383ed71...|2018-11-24 01:35:00|  66498|     508|    latest|    1|       0|        7|\n",
      "|50b581cac0dcc1672...|2018-11-24 01:37:00|  77000|     244|    latest|    1|       0|        7|\n",
      "|277c3d058cb0490fa...|2018-11-24 01:39:00|  46028|     190|    latest|    0|       0|        7|\n",
      "|bde2abe34297af7e0...|2018-11-24 01:44:00|  84806|     190|    latest|    0|       0|        7|\n",
      "|bdc3472e51887357a...|2018-11-24 01:47:00|  73076|     473|    latest|    0|       0|        7|\n",
      "|9a14ec361fce610fe...|2018-11-24 01:49:00|  85634|      32|    latest|    1|       0|        7|\n",
      "|b2ad0e581e0195bcb...|2018-11-24 01:50:00|  82257|       3|    latest|    1|       0|        7|\n",
      "|a2b490ed6409a7b13...|2018-11-24 01:53:00|  64412|      38|    latest|    0|       0|        7|\n",
      "|298ba172091b07c23...|2018-11-24 01:54:00|  34412|       3|    latest|    1|       0|        7|\n",
      "|e1f311762441bb48d...|2018-11-24 01:58:00|  16929|     372|    latest|    0|       0|        7|\n",
      "|ec9858da4637f2291...|2018-11-24 02:04:00|  88589|     249|    latest|    0|       0|        7|\n",
      "|02f38b70d904d7c0b...|2018-11-24 02:10:00|  59643|     465|    latest|    1|       0|        7|\n",
      "|0ef369271418089b4...|2018-11-24 02:15:00|  38266|     190|    latest|    1|       0|        7|\n",
      "|5d2903364418c3c09...|2018-11-24 02:17:00|  78796|     242|    latest|    1|       0|        7|\n",
      "|01b7ebbc8e1990be2...|2018-11-24 02:21:00|  16918|       3|    latest|    1|       0|        7|\n",
      "|56ce94779a45b9dec...|2018-11-24 02:24:00|  68640|     190|    latest|    0|       0|        7|\n",
      "|b24f4ae2eb41a573e...|2018-11-24 02:28:00|  48834|     371|    latest|    0|       0|        7|\n",
      "|b6e37fd3a77259371...|2018-11-24 02:32:00|  90201|     190|    latest|    1|       0|        7|\n",
      "|71ec89d6a2089545c...|2018-11-24 02:34:00|  49039|     371|    latest|    1|       0|        7|\n",
      "|99356a4254135f494...|2018-11-24 02:45:00|  10276|     207|    latest|    0|       0|        7|\n",
      "+--------------------+-------------------+-------+--------+----------+-----+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Add New Columns  - Day of Week\n",
    "newcolumn_df = latest_os_df.withColumn(\"dayofweek\", F.dayofweek(\"impression_time\"))\n",
    "newcolumn_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|dayofweek|total_clicks|\n",
      "+---------+------------+\n",
      "|        1|         798|\n",
      "|        6|         696|\n",
      "|        3|         931|\n",
      "|        5|         770|\n",
      "|        4|         654|\n",
      "|        7|         743|\n",
      "|        2|         790|\n",
      "+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Aggregate: Total Clicks per Day of Week\n",
    "total_clicks_df = newcolumn_df.groupBy(\"dayofweek\",).agg(F.sum(\"is_click\").alias(\"total_clicks\"))\n",
    "total_clicks_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save as Delta table\n",
    "total_clicks_df.write.format(\"delta\").mode(\"overwrite\").save(\"data/tranformation_impressions_delta_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|dayofweek|total_clicks|\n",
      "+---------+------------+\n",
      "|        1|         798|\n",
      "|        6|         696|\n",
      "|        3|         931|\n",
      "|        5|         770|\n",
      "|        4|         654|\n",
      "|        7|         743|\n",
      "|        2|         790|\n",
      "+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Delta table\n",
    "total_clicks_df = spark.read.format(\"delta\").load(\"data/tranformation_impressions_delta_table\")\n",
    "total_clicks_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
